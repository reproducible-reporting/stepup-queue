{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to StepUp Queue","text":"<p>StepUp Queue is an experimental extension of StepUp Core to integrate queued jobs into a workflow. Currently, it only supports integration with SLURM, but it is designed to be extensible to other job schedulers.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":"<p>All notable changes to StepUp Queue will be documented on this page.</p> <p>The format is based on Keep a Changelog, and this project adheres to Effort-based Versioning. (Changes to features documented as \u201cexperimental\u201d will not increment macro and meso version numbers.)</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":"<p>(no changes yet)</p>"},{"location":"changelog/#v1.0.1","title":"1.0.1 - 2025-05-11","text":"<p>This is a minor cleanup release, mainly testing the release process.</p>"},{"location":"changelog/#v1.0.0","title":"1.0.0 - 2025-05-11","text":"<p>This is an initial and experimental release of StepUp Queue.</p>"},{"location":"changelog/#added","title":"Added","text":"<p>Initial release of StepUp Queue. The initial package is based on the <code>sbatch-wait</code> script from Parman. It was adapted to integrate well with StepUp Core 3. This release also features the <code>stepup canceljobs</code> tool, which was not present in Parman.</p>"},{"location":"development/","title":"Developer Notes","text":"<p>If you would like to contribute, please read CONTRIBUTING.md.</p>"},{"location":"development/#development-environment","title":"Development environment","text":"<p>If you break your development environment, you can discard it by running <code>git clean -dfX</code> and repeating the instructions below.</p> <p>A local installation for testing and development can be installed using the following commands:</p> <pre><code>git clone git@github.com:reproducible-reporting/stepup-queue.git\ncd stepup-queue\npre-commit install\npython -m venv venv\n</code></pre> <p>Put the following lines in <code>.envrc</code>:</p> <pre><code>source venv/bin/activate\nexport XDG_CACHE_HOME=\"${VIRTUAL_ENV}/cache\"\nexport STEPUP_DEBUG=\"1\"\nexport STEPUP_SYNC_RPC_TIMEOUT=\"30\"\n</code></pre> <p>Finally, run the following commands:</p> <pre><code>direnv allow\npip install -U pip\npip install -e .\npip install -e ../stepup-core[dev] --config-settings editable_mode=strict  # optional\n</code></pre>"},{"location":"development/#tests","title":"Tests","text":"<p>We use pytest, so you can run the tests as follows:</p> <pre><code>pytest -vv\n</code></pre>"},{"location":"development/#documentation","title":"Documentation","text":"<p>The documentation is created using MkDocs. mike is used to manage documentation of different versions</p> <p>Edit the documentation Markdown files with a live preview by running:</p> <pre><code>mkdocs serve\n</code></pre> <p>(Keep this running.) Then open the live preview in your browser at http://127.0.0.1:8000/ and edit Markdown files in your IDE.</p> <p>Please, use Semantic Line Breaks because it facilitates reviewing documentation changes.</p>"},{"location":"development/#tutorial-example-outputs","title":"Tutorial Example Outputs","text":"<p>If you wish to regenerate the output of the examples, run <code>stepup</code> in the <code>docs</code> directory:</p> <pre><code>cd docs\nstepup\n</code></pre> <p>(Keep this running.) Then open the live preview in your browser: http://127.0.0.1:8000/ and edit Markdown files in your IDE.</p> <p>Please, use Semantic Line Breaks because it results in cleaner file diffs when editing documentation.</p>"},{"location":"development/#how-to-make-a-release","title":"How to Make a Release","text":"<ul> <li>Mark the release in <code>docs/changelog.md</code>.   Do not forget to extend the links at the bottom of the file.</li> <li>Make a new commit and tag it with <code>vX.Y.Z</code>.</li> <li>Trigger the PyPI GitHub Action: <code>git push origin main --tags</code>.</li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>Requirements:</p> <ul> <li>POSIX operating system: Linux, macOS or WSL.   StepUp cannot run natively on Windows.</li> <li>Python \u2265 3.11</li> <li>Pip</li> <li>StepUp Core &gt;= 3.0.0</li> </ul> <p>It is assumed that you know how to use Pip. We recommend performing the installation in a Python virtual environment and activating such environments with direnv.</p> <p>StepUp Queue can be installed with:</p> <pre><code>pip install stepup-queue\n</code></pre>"},{"location":"license/","title":"License","text":""},{"location":"license/#source-code-license","title":"Source code license","text":"<p>StepUp Queue is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.</p> <p>StepUp Queue is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.</p> <p>You should have received a copy of the GNU General Public License along with this program. If not, see https://www.gnu.org/licenses/.</p>"},{"location":"license/#documentation-license","title":"Documentation license","text":"<p>StepUp Queue\u2019s documentation is distributed under the Creative Commons CC BY-SA 4.0 license.</p>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#the-sbatch-function","title":"The <code>sbatch</code> Function","text":"<p>If you want to submit a job to the queue as part of a StepUp workflow, you must first prepare a directory with a job script called <code>slurmjob.sh</code>. This can be either a static file or the output of a previous step in the workflow. For simplicity, the following example assumes that the job script is static:</p> <pre><code>from stepup.core.api import static\nfrom stepup.queue.api import sbatch\n\nstatic(\"compute/\", \"compute/slurmjob.sh\")\nsbatch(\"compute/\")\n</code></pre> <p>All arguments to <code>sbatch</code> must be included in the <code>slurmjob.sh</code> script with <code>#SBATCH</code> directives. You can only submit one job from a given directory.</p> <p>When the workflow is executed, the <code>sbatch</code> step will submit the job to the queue. It will then wait for the job to complete, just like <code>sbatch --wait</code>. Unlike <code>sbatch --wait</code>, it can also wait for a previously submitted job to complete. This can be useful when the workflow gets killed for some reason.</p> <p>The standard output and error of the job are written to <code>slurmjob.out</code> and <code>slurmjob.err</code>, respectively.</p> <p>The current status of the job is written to (and read from) the <code>slurmjob.log</code> file. The job will not be resubmitted if <code>slurmjob.log</code> exists. Instead, it will wait for the job to complete without resubmitting it. You can remove <code>slurmjob.log</code> to ensure that the job is resubmitted, but this is off course dangerous if the job is still running.</p>"},{"location":"usage/#simple-example","title":"Simple Example","text":"<p>A simple working example with static and dynamically generated job scripts can be found in the <code>examples/slurm/</code> directory.</p> <pre><code>#!/usr/bin/env python3\n\nfrom stepup.core.api import mkdir, render_jinja, static\nfrom stepup.queue.api import sbatch\n\n# First an example of a static job script, i.e. already present on disk.\nstatic(\"static/\", \"static/slurmjob.sh\")\nsbatch(\"static\")\n\n# Now an example of a job script that is generated from a template.\nstatic(\"dynamic-template.sh\")\nfor i in range(1, 4):\n    mkdir(f\"dynamic{i}/\")\n    render_jinja(\"dynamic-template.sh\", {\"field\": i}, f\"dynamic{i}/slurmjob.sh\")\n    sbatch(f\"dynamic{i}/\")\n</code></pre>"},{"location":"usage/#killing-running-jobs","title":"Killing running jobs","text":"<p>If you decide that you want to interrupt the workflow and cancel all running SLURM jobs, it is not enough to simply kill or stop StepUp. You must also cancel the jobs in the SLURM queue. This can be done by running the following command from the top-level directory of the workflow:</p> <pre><code>stepup canceljobs\n</code></pre> <p>It is part of the design of StepUp Queue\u2019s not to automatically cancel jobs when the workflow is interrupted. It is quite common for a workflow to be interrupted by accident or due to a technical problem. In this case, it would be inefficient to also cancel running jobs, which may still be doing useful work. Instead, they continue to run and you can restart the StepUp workflow to pick up where it left off.</p> <p>After having cancelled jobs, it is still your responsibility to clean up files in the workflow. Removing them is not always desirable, so this is not done automatically.</p>"},{"location":"usage/#technical-details","title":"Technical Details","text":"<p>The timestamps in the log file have a low resolution of about 1 minute. The job state is only checked every 30\u201340 seconds to avoid overloading the Job Scheduler. Information from <code>slurmjob.log</code> is maximally reused to avoid unnecessary <code>scontrol</code> calls.</p> <p>The status of the job is inferred from <code>scontrol show job</code>, if relevant with a <code>--cluster</code> argument. To further minimize the number of <code>scontrol</code> calls in a parallel workflow, its output is cached and stored in <code>~/.cache/stepup-queue</code>. The cached results are reused by all <code>sbatch</code> actions, so the number of <code>scontrol</code> calls is independent of the number of jobs running in parallel.</p> <p>The time between two <code>scontrol</code> calls (per cluster) can be controlled with the <code>STEPUP_SBATCH_CACHE_TIMEOUT</code> environment variable, which is <code>\"30\"</code> (seconds) by default. Increase this value if you want to reduce the burden on Slurm.</p> <p>The cached output of <code>scontrol</code> is checked with a randomized polling interval. The randomization guarantees that concurrent calls to <code>scontrol</code> (for multiple clusters) will not all coincide. The polling time can be controlled with two additional environment variables:</p> <ul> <li><code>STEPUP_SBATCH_POLLING_INTERVAL</code> = the minimal polling interval in seconds, default is <code>\"10\"</code>.</li> <li><code>STEPUP_SBATCH_TIME_MARGIN</code> = the width of the uniform distribution for the polling interval   in seconds, default is <code>\"5\"</code>.</li> </ul>"}]}