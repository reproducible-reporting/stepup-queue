{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to StepUp Queue","text":"<p>StepUp Queue is an experimental extension of StepUp Core to integrate queued jobs into a workflow. Currently, it only supports integration with SLURM, but it is designed to be extensible to other job schedulers.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":"<p>All notable changes to StepUp Queue will be documented on this page.</p> <p>The format is based on Keep a Changelog, and this project adheres to Effort-based Versioning. (Changes to features documented as \u201cexperimental\u201d will not increment macro and meso version numbers.)</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":"<p>(no changes yet)</p>"},{"location":"changelog/#v1.0.2","title":"1.0.2 - 2025-05-14","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Option to specify the extension of the job script.</li> <li>Wrap all job scripts to record their return code.</li> <li>Detect when inputs of jobs have changed + optional resubmission.</li> <li>Option to load resource configurations before sbatch is called.</li> <li>More detailed examples, including a self-submitting workflow job.</li> </ul>"},{"location":"changelog/#v1.0.1","title":"1.0.1 - 2025-05-11","text":"<p>This is a minor cleanup release, mainly testing the release process.</p>"},{"location":"changelog/#v1.0.0","title":"1.0.0 - 2025-05-11","text":"<p>This is an initial and experimental release of StepUp Queue.</p>"},{"location":"changelog/#added_1","title":"Added","text":"<p>Initial release of StepUp Queue. The initial package is based on the <code>sbatch-wait</code> script from Parman. It was adapted to integrate well with StepUp Core 3. This release also features the <code>stepup canceljobs</code> tool, which was not present in Parman.</p>"},{"location":"development/","title":"Developer Notes","text":"<p>If you would like to contribute, please read CONTRIBUTING.md.</p>"},{"location":"development/#development-environment","title":"Development environment","text":"<p>If you break your development environment, you can discard it by running <code>git clean -dfX</code> and repeating the instructions below.</p> <p>A local installation for testing and development can be installed using the following commands:</p> <pre><code>git clone git@github.com:reproducible-reporting/stepup-queue.git\ncd stepup-queue\npre-commit install\npython -m venv venv\n</code></pre> <p>Put the following lines in <code>.envrc</code>:</p> <pre><code>source venv/bin/activate\nexport XDG_CACHE_HOME=\"${VIRTUAL_ENV}/cache\"\nexport STEPUP_DEBUG=\"1\"\nexport STEPUP_SYNC_RPC_TIMEOUT=\"30\"\n</code></pre> <p>Finally, run the following commands:</p> <pre><code>direnv allow\npip install -U pip\npip install -e .\npip install -e ../stepup-core[dev] --config-settings editable_mode=strict  # optional\n</code></pre>"},{"location":"development/#tests","title":"Tests","text":"<p>We use pytest, so you can run the tests as follows:</p> <pre><code>pytest -vv\n</code></pre>"},{"location":"development/#documentation","title":"Documentation","text":"<p>The documentation is created using MkDocs. mike is used to manage documentation of different versions</p> <p>Edit the documentation Markdown files with a live preview by running:</p> <pre><code>mkdocs serve\n</code></pre> <p>(Keep this running.) Then open the live preview in your browser at http://127.0.0.1:8000/ and edit Markdown files in your IDE.</p> <p>Please, use Semantic Line Breaks because it facilitates reviewing documentation changes.</p>"},{"location":"development/#tutorial-example-outputs","title":"Tutorial Example Outputs","text":"<p>If you wish to regenerate the output of the examples, run <code>stepup</code> in the <code>docs</code> directory:</p> <pre><code>cd docs\nstepup\n</code></pre> <p>(Keep this running.) Then open the live preview in your browser: http://127.0.0.1:8000/ and edit Markdown files in your IDE.</p> <p>Please, use Semantic Line Breaks because it results in cleaner file diffs when editing documentation.</p>"},{"location":"development/#how-to-make-a-release","title":"How to Make a Release","text":"<ul> <li>Mark the release in <code>docs/changelog.md</code>.   Do not forget to extend the links at the bottom of the file.</li> <li>Make a new commit and tag it with <code>vX.Y.Z</code>.</li> <li>Trigger the PyPI GitHub Action: <code>git push origin main --tags</code>.</li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>Requirements:</p> <ul> <li>POSIX operating system: Linux, macOS or WSL.   StepUp cannot run natively on Windows.</li> <li>Python \u2265 3.11</li> <li>Pip</li> <li>StepUp Core &gt;= 3.0.0</li> </ul> <p>It is assumed that you know how to use Pip. We recommend performing the installation in a Python virtual environment and activating such environments with direnv.</p> <p>StepUp Queue can be installed with:</p> <pre><code>pip install stepup-queue\n</code></pre>"},{"location":"license/","title":"License","text":""},{"location":"license/#source-code-license","title":"Source code license","text":"<p>StepUp Queue is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.</p> <p>StepUp Queue is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.</p> <p>You should have received a copy of the GNU General Public License along with this program. If not, see https://www.gnu.org/licenses/.</p>"},{"location":"license/#documentation-license","title":"Documentation license","text":"<p>StepUp Queue\u2019s documentation is distributed under the Creative Commons CC BY-SA 4.0 license.</p>"},{"location":"stepup.queue.api/","title":"stepup.queue.api","text":"<p>StepUp Queue API functions to build workflows.</p>"},{"location":"stepup.queue.api/#stepup.queue.api.sbatch","title":"<code>sbatch(workdir, *, ext='.sh', rc=None, inp=(), env=(), out=(), vol=(), optional=False, pool=None, block=False)</code>","text":"<p>Submit a SLURM job script.</p> <p>The following filename conventions are used in the given working directory:</p> <ul> <li><code>slurmjob{ext}</code> is the job script to be submitted.</li> <li><code>slurmjob.log</code> is StepUp Queue\u2019s log file keeping track of the job\u2019s status.</li> <li><code>slurmjob.out</code> is the job\u2019s output file (written by SLURM).</li> <li><code>slurmjob.err</code> is the job\u2019s error file (written by SLURM).</li> <li><code>slurmjob.ret</code> is the job\u2019s return code (written by a wrapper script).</li> </ul> <p>Hence, you can only have one job script per working directory, and it is strongly recommended to use meaningful directory names. Within the directory, try to use as much as possible exactly the same file names for all jobs.</p> <p>When the step is executed, it will submit the job or skip this if it was done before. If submitted, the step will wait until the job is finished. If already finished, the step will essentially be a no-op.</p> <p>See <code>step()</code> documentation in StepUp Core for all optional arguments. and the return value.</p> <p>Parameters:</p> <ul> <li> <code>ext</code>               (<code>str</code>, default:                   <code>'.sh'</code> )           \u2013            <p>The filename extension of the jobscript. The full name is <code>f\"slurmjob{ext}\"</code>. Extensions <code>.log</code>, <code>.out</code>, <code>.err</code> and <code>.ret</code> are not allowed.</p> </li> <li> <code>rc</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>A resource configuration to be executed before calling sbatch. This will be executed in the same shell, right before the sbatch command. For example, you can run <code>module swap cluster/something</code> or prepare other resources. If multiple instructions are needed, put them in a file, e.g. <code>rc.sh</code> and pass it here as <code>source rc.sh</code>. In this case, you usually also want to include <code>rc.sh</code> in the <code>inp</code> list.</p> </li> </ul> Source code in <code>stepup/queue/api.py</code> <pre><code>def sbatch(\n    workdir: str,\n    *,\n    ext: str = \".sh\",\n    rc: str | None = None,\n    inp: Collection[str] | str = (),\n    env: Collection[str] | str = (),\n    out: Collection[str] | str = (),\n    vol: Collection[str] | str = (),\n    optional: bool = False,\n    pool: str | None = None,\n    block: bool = False,\n):\n    \"\"\"Submit a SLURM job script.\n\n    The following filename conventions are used in the given working directory:\n\n    - `slurmjob{ext}` is the job script to be submitted.\n    - `slurmjob.log` is StepUp Queue's log file keeping track of the job's status.\n    - `slurmjob.out` is the job's output file (written by SLURM).\n    - `slurmjob.err` is the job's error file (written by SLURM).\n    - `slurmjob.ret` is the job's return code (written by a wrapper script).\n\n    Hence, you can only have one job script per working directory,\n    and it is strongly recommended to use meaningful directory names.\n    Within the directory, try to use as much as possible exactly the same file names for all jobs.\n\n    When the step is executed, it will submit the job or skip this if it was done before.\n    If submitted, the step will wait until the job is finished.\n    If already finished, the step will essentially be a no-op.\n\n    See `step()` documentation in StepUp Core for all optional arguments.\n    and the return value.\n\n    Parameters\n    ----------\n    ext\n        The filename extension of the jobscript.\n        The full name is `f\"slurmjob{ext}\"`.\n        Extensions `.log`, `.out`, `.err` and `.ret` are not allowed.\n    rc\n        A resource configuration to be executed before calling sbatch.\n        This will be executed in the same shell, right before the sbatch command.\n        For example, you can run `module swap cluster/something`\n        or prepare other resources.\n        If multiple instructions are needed, put them in a file, e.g. `rc.sh`\n        and pass it here as `source rc.sh`.\n        In this case, you usually also want to include `rc.sh` in the `inp` list.\n    \"\"\"\n    if ext == \"\":\n        ext = \".sh\"\n    elif ext[0] != \".\":\n        ext = f\".{ext}\"\n    if ext in [\".log\", \".out\", \".err\", \".ret\"]:\n        raise ValueError(f\"Invalid extension {ext}. The extension must not be .log, .out or .err.\")\n    action = \"sbatch\"\n    if ext != \".sh\":\n        action += f\" {ext}\"\n    if rc is not None:\n        action += f\" --rc={shlex.quote(rc)}\"\n    return step(\n        action,\n        inp=[f\"slurmjob{ext}\", *string_to_list(inp)],\n        env=env,\n        out=[\"slurmjob.out\", \"slurmjob.err\", \"slurmjob.ret\", *string_to_list(out)],\n        vol=[\"slurmjob.log\", *string_to_list(vol)],\n        workdir=workdir,\n        optional=optional,\n        pool=pool,\n        block=block,\n    )\n</code></pre>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#the-sbatch-function","title":"The <code>sbatch</code> Function","text":"<p>If you want to submit a job to the queue as part of a StepUp workflow, you must first prepare a directory with a job script called <code>slurmjob.sh</code>. This can be either a static file or the output of a previous step in the workflow. The function <code>sbatch()</code> will then submit the job to the queue. For simplicity, the following example assumes that the job script is static:</p> <pre><code>from stepup.core.api import static\nfrom stepup.queue.api import sbatch\n\nstatic(\"compute/\", \"compute/slurmjob.sh\")\nsbatch(\"compute/\")\n</code></pre> <p>All arguments to the <code>sbatch</code> command of SLURM must be included in the <code>slurmjob.sh</code> script with <code>#SBATCH</code> directives. You can only submit one job from a given directory.</p> <p>When the workflow is executed, the <code>sbatch</code> step will submit the job to the queue. It will then wait for the job to complete, just like <code>sbatch --wait</code>. Unlike <code>sbatch --wait</code>, it can also wait for a previously submitted job to complete. This can be useful when the workflow gets killed for some reason.</p> <p>The standard output and error of the job are written to <code>slurmjob.out</code> and <code>slurmjob.err</code>, respectively.</p> <p>The current status of the job is written to (and read from) the <code>slurmjob.log</code> file. By default, the job is not resubmitted if <code>slurmjob.log</code> exists. Instead, it waits for the job to complete without resubmitting it. You can remove <code>slurmjob.log</code> to ensure that the job is resubmitted, but this is obviously dangerous if the job is still running.</p> <p>If the inputs of the job specified with <code>sbatch(\"compute/\", inp=[\"inp.txt\"])</code> have changed, restarting the workflow will by default raise an exception. Ideally, you should clean up old outputs before restarting the workflow, and check that you really want to remove the data before doing so. If you feel this is overly cautious, you can set the <code>STEPUP_QUEUE_RESUBMIT_CHANGED_INPUTS</code> environment variable to <code>\"yes\"</code> to allow the workflow to resubmit jobs with changed inputs. Old outputs are not removed before resubmission. It is assumed that your job script will perform the necessary cleanup itself.</p>"},{"location":"usage/#examples","title":"Examples","text":"<ul> <li> <p>A simple example with static and dynamically generated job scripts   can be found in the <code>examples/slurm-basic/</code>.</p> </li> <li> <p>The example <code>examples/slurm-perpetual/</code>   shows how to run StepUp itself as a job in the queue,   which cancels and submits itself again when nearing the wall time limit,   if the workflow has not yet completed.</p> </li> </ul>"},{"location":"usage/#killing-running-jobs","title":"Killing running jobs","text":"<p>If you decide that you want to interrupt the workflow and cancel all running SLURM jobs, it is not enough to simply kill or stop StepUp. You must also cancel the jobs in the SLURM queue. This can be done by running the following command from the top-level directory of the workflow:</p> <pre><code>stepup canceljobs\n</code></pre> <p>It is part of the design of StepUp Queue\u2019s not to automatically cancel jobs when the workflow is interrupted. It is quite common for a workflow to be interrupted by accident or for technical reasons. In this case, it would be inefficient to also cancel running jobs, which may still be doing useful work. Instead, jobs continue to run and you can restart the StepUp workflow to pick up where it left off.</p> <p>After having cancelled jobs, it is still your responsibility to clean up files in the workflow. Removing them is not always desirable, so this is not done automatically.</p>"},{"location":"usage/#technical-details","title":"Technical Details","text":"<p>The timestamps in the log file have a low resolution of about 1 minute. The job state is only checked every 30\u201340 seconds to avoid overloading the Job Scheduler. Information from <code>slurmjob.log</code> is maximally reused to avoid unnecessary <code>scontrol</code> calls.</p> <p>The status of the job is inferred from <code>scontrol show job</code>, if relevant with a <code>--cluster</code> argument. To further minimize the number of <code>scontrol</code> calls in a parallel workflow, its output is cached and stored in <code>~/.cache/stepup-queue</code>. The cached results are reused by all <code>sbatch</code> actions, so the number of <code>scontrol</code> calls is independent of the number of jobs running in parallel.</p> <p>The time between two <code>scontrol</code> calls (per cluster) can be controlled with the <code>STEPUP_SBATCH_CACHE_TIMEOUT</code> environment variable, which is <code>\"30\"</code> (seconds) by default. Increase this value if you want to reduce the burden on Slurm.</p> <p>The cached output of <code>scontrol</code> is checked with a randomized polling interval. The randomization guarantees that concurrent calls to <code>scontrol</code> (for multiple clusters) will not all coincide. The polling time can be controlled with two additional environment variables:</p> <ul> <li><code>STEPUP_SBATCH_POLLING_INTERVAL</code> = the minimal polling interval in seconds, default is <code>\"10\"</code>.</li> <li><code>STEPUP_SBATCH_TIME_MARGIN</code> = the width of the uniform distribution for the polling interval   in seconds, default is <code>\"5\"</code>.</li> </ul>"},{"location":"examples/slurm-basic/","title":"Basic SLURM example","text":"<p>The latest version of this example can be found at: https://github.com/reproducible-reporting/stepup-queue/tree/main/docs/examples/slurm-basic/</p> <p>This example shows how to use StepUp to run job scripts, which can be either manually written (static) or generated from a template (dynamic). Since these jobs only take a few seconds and don\u2019t perform any computations, they allow for a quick demonstration of StepUp Queue\u2019s features.</p>"},{"location":"examples/slurm-basic/#files","title":"Files","text":"<pre><code>.\n\u251c\u2500\u2500 dynamic-template.sh\n\u251c\u2500\u2500 fail\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 slurmjob.sh\n\u251c\u2500\u2500 pass\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 slurmjob.py\n\u251c\u2500\u2500 plan.py\n\u2514\u2500\u2500 README.md\n</code></pre> <p><code>plan.py</code> is a Python script that defines the workflow:</p> <pre><code>#!/usr/bin/env python3\n\nfrom stepup.core.api import mkdir, render_jinja, static\nfrom stepup.queue.api import sbatch\n\n# Two examples of a static job script, i.e. already present on disk.\nstatic(\"pass/\", \"pass/slurmjob.py\")\nsbatch(\"pass\", ext=\".py\")\nstatic(\"fail/\", \"fail/slurmjob.sh\")\nsbatch(\"fail\")\n\n# Example of job scripts generated from a template.\nstatic(\"dynamic-template.sh\")\nfor i in range(1, 4):\n    mkdir(f\"dynamic{i}/\")\n    render_jinja(\"dynamic-template.sh\", {\"field\": i}, f\"dynamic{i}/slurmjob.sh\")\n    # You can use the rc option to load an environment before calling sbatch.\n    # Use this only if it cannot be done in the job script itself.\n    sbatch(f\"dynamic{i}/\", rc=\"module swap cluster/doduo\")\n</code></pre> <p>The job <code>fail/slurmjob.sh</code> is a static job script that fails with a non-zero exit code, which is correctly handled by StepUp Queue:</p> <pre><code>#!/usr/bin/env bash\n#SBATCH --job-name fail\n#SBATCH --nodes=1\n#SBATCH --num-tasks=1\n#SBATCH --cpus-per-task=1\n\necho \"This job will fail\"\nexit 1\n</code></pre> <p>The job <code>pass/slurmjob.py</code> shows how to write a Job script in Python:</p> <pre><code>#!/usr/bin/env python3\n#SBATCH --job-name pass\n#SBATCH --nodes=1\n#SBATCH --num-tasks=1\n#SBATCH --cpus-per-task=1\n\nfrom time import sleep\n\nprint(\"Hello from static job\")\nsleep(5)\nprint(\"Goodbye from static job\")\n</code></pre> <p>The file <code>dynamic-template.sh</code> is a template from which actual job scripts are generated:</p> <pre><code>#!/usr/bin/env bash\n#SBATCH --job-name 'dyn{{ field }}'\n#SBATCH --nodes=1\n#SBATCH --num-tasks=1\n#SBATCH --cpus-per-task=1\n\necho \"Hello from dynamic job {{ field }}\"\nsleep 5\necho \"Goodbye from dynamic job {{ field }}\"\n</code></pre> <p>Note that <code>render_jinja</code> can be used to render any kind of text-based file from a template, such as inputs to computational tools, configuration files, etc.</p>"},{"location":"examples/slurm-perpetual/","title":"Perpetual SLURM Workflow Job","text":"<p>The latest version of this example can be found at: https://github.com/reproducible-reporting/stepup-queue/tree/main/docs/examples/slurm-perpetual/</p> <p>For extensive workflows, it is often useful to submit the workflow itself to the queue as a job. It is generally preferred to run the workflow on a compute node of the cluster, as this allows for better resource management and prevents overloading the login node. However, most clusters impose a limit on the maximum wall time of a job, which can result in the workflow job being interrupted. This example shows how to work around this limitation by using a perpetual self-submitting job.</p> <p>At the start of the job, a background process is launched that will end StepUp before the wall time limit is reached if StepUp has not ended on its own. When StepUp is interrupted, a temporary file is created. This file is later used as a signal that the workflow job needs to be resubmitted. This technique can be used with any type of job and is not specific to StepUp.</p> <p>Here, we use a very short runtime to quickly demonstrate StepUp Queue\u2019s features. In practice, you can let the StepUp job run for several hours or even days at a time, and stop it about 30 minutes before the wall time limit is reached.</p>"},{"location":"examples/slurm-perpetual/#files","title":"Files","text":"<pre><code>.\n\u251c\u2500\u2500 plan.py\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 step1\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 slurmjob.sh\n\u251c\u2500\u2500 step2\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 slurmjob.sh\n\u2514\u2500\u2500 workflow.sh\n</code></pre> <p><code>plan.py</code> is a Python script that defines the workflow:</p> <pre><code>#!/usr/bin/env python3\n\nfrom stepup.core.api import static\nfrom stepup.queue.api import sbatch\n\nstatic(\"step1/\", \"step1/slurmjob.sh\", \"step2/\", \"step2/slurmjob.sh\")\nsbatch(\"step1/\", out=\"../intermediate.txt\")\nsbatch(\"step2/\", inp=\"../intermediate.txt\")\n</code></pre> <p><code>step1/slurmjob.sh</code> is the first SLURM job:</p> <pre><code>#!/usr/bin/env bash\n#SBATCH --job-name step1\n#SBATCH --nodes=1\n#SBATCH --num-tasks=1\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:02:00\n\n# Give the CPU a break...\nsleep 30\necho Done &gt; ../intermediate.txt\n</code></pre> <p><code>step2/slurmjob.sh</code> is the second SLURM job:</p> <pre><code>#!/usr/bin/env bash\n#SBATCH --job-name step2\n#SBATCH --nodes=1\n#SBATCH --num-tasks=1\n#SBATCH --cpus-per-task=1\n\n#SBATCH --time=00:02:00\n\n# Give the CPU a break...\nsleep 30\ncat ../intermediate.txt\n</code></pre> <p><code>workflow.sh</code> is the SLURM job script that runs the workflow:</p> <pre><code>#!/usr/bin/env bash\n#SBATCH --job-name perpetual-workflow\n#SBATCH --nodes=1\n#SBATCH --num-tasks=1\n#SBATCH --cpus-per-task=1\n#SBATCH --output=workflow-%j.out\n#SBATCH --time=00:01:00\n\n# In production, --time=00:12:00 is a reasonable time limit.\n\n# If needed, load required modules and activate a relevant virtual environment.\n# For example:\n# module load Python/3.12.3\n# activate venv/bin/activate\n\n# Create a temporary directory to store a file that will be used as a flag\n# to indicate that resubmission is needed.\nSTEPUP_QUEUE_FLAG_DIR=$(mktemp -d)\necho \"Created temporary directory: $STEPUP_QUEUE_FLAG_DIR\"\ntrap 'rm -rv \"$STEPUP_QUEUE_FLAG_DIR\"' EXIT\n\n# Start a background process that will end stepup near the wall time limit.\n# The first shutdown will wait for running steps to completed.\n# The second will forcefully terminate remaining running steps.\necho \"Starting background process to monitor wall time.\"\n(\n    sleep 30;  # In production, 39600 seconds is reasonable.\n    touch ${STEPUP_QUEUE_FLAG_DIR}/resubmit;\n    stepup shutdown;\n    sleep 10;  # In production, 300 seconds is reasonable.\n    stepup shutdown\n) &amp;\nBGPID=$!\ntrap \"kill $BGPID\" EXIT\n\n# Start StepUp with 5 workers.\n# This means that at most 5 jobs will be submitted concurrently.\n# You can adjust the number of workers based on your needs.\n# In fact, because this example is simple, a single worker would be sufficient.\n# Note that the number of workers is unrelated\n# to the single core used by this workflow script.\necho \"Starting stepup with a maximum of 5 concurrent jobs.\"\nstepup boot -n 5\n\n# Use the temporary file to determine if the workflow script must be resubmitted.\necho \"Checking if stepup was forcibly stopped.\"\nif [ -f ${STEPUP_QUEUE_FLAG_DIR}/resubmit ]; then\n    echo \"Resubmitting job script to let StepUp finalize the workflow.\"\n    sbatch workflow.sh\nelse\n    echo \"Stepup was stopped gracefully.\"\nfi\n</code></pre>"}]}